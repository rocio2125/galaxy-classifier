version: '3.8'

services:
  # 1. BASE DE DATOS (Local)
  db:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: galaxy_db
    ports:
      - "5432:5432"
    volumes:
      - ./postgres_data:/var/lib/postgresql/data

  # 2. API FLASK (Backend)
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: galaxy_api
    ports:
      - "5000:5000" # En tu navegador: localhost:5000
    volumes:
      # (Opcional) Para desarrollo: ver cambios en el código sin reconstruir
      - .:/app
      # CAMBIO 2: Persistencia del modelo de Hugging Face
      # Mapeamos tu carpeta local 'models' a la carpeta de caché interna
      - ./models:/app/hf_cache
    environment:
      DATABASE_URL: postgresql://user:password@db:5432/galaxy_db
      SECRET_KEY: local_secret
      # CAMBIO 3: Configuramos Hugging Face para usar la carpeta del volumen
      HF_HOME: /app/hf_cache
      # CAMBIO 4: Si tu modelo es PRIVADO, descomenta la linea de abajo y pon tu token
      # HF_TOKEN: "hf_tu_token_aqui"
    depends_on:
      - db

  # 3. STREAMLIT (Frontend)
  frontend:
    build:
      context: .
      dockerfile: src/frontend/Dockerfile
    container_name: galaxy_frontend
    ports:
      - "8501:8501" # En tu navegador: localhost:8501
    environment:
      # OJO: Streamlit (dentro de docker) llama a la API por su nombre de servicio 'api',
      # cambiar luego a algo parecido a https://galaxy-api.onrender.com/predict
      API_URL: http://api:5000/predict
    depends_on:
      - api
